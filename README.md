# creative_experience2021
縄田研究室 2021年度の創造実験．
webテキストのクラスタリングを行った．

### purpose
群知能についての理解を深めるとともに，群知能のデータマイニングにおける応用の可能性を確認する．

今回は群知能の例としてAntTree法を用いた．また，代表的なクラスタリング手法であるK-Means法との比較を行った．


# description
1. webテキストのコーパスをMeCabを用いて品詞を絞って形態素解析
    1. wakati/wakati-hinshi.py
2. コーパスごとに出現した単語をFastTextを用いて分散表現に変換
3. トピックごとに頻出した単語やそのベクトルのプロットを確認
    1. data_test/get_docWords.py
    1. data_test/make_freq_map.py
4. 単語ベクトルの総和をその文書のベクトルとして，オブジェクトを保存
    1. save_vectorDatas.py
5. 上記のオブジェクトをK-Means法とAntTree法に与えて結果を比較
    1. datas/sample.csv
    1. datas/textlist.csv
    1. datas/genrelist.csv
    1. AntTree/AntTree_Script.py
    1. KMeans/k-means.py
 
 
ただし，以下のとおりである．
* K-Means法はscikit-learn内のものを使用した．
* MeCabではipa辞書を用いた．
* FastTextのモデルは日本語Wikipediaを用いて学習させたもの(300次元)を用いた．
* FastTextのモデルや，その作成に関するコード，実際に用いたコーパスについては省略する．
* アルゴリズムに関してはスライドや参考文献を参照．

# 動作環境
|動作環境|
|:--:|
|windows10|
|python 3.9.6|

|パッケージ|
|:--:|
|gensim 4.0.1|
|mecab 0.996.3|
|sklearn 0.0|

# result
### データの表現について

|kaden-channel|Movie-enter|Sports-watch|
|:--:|:--:|:--:|
|話題|映画|日本|
|人|人|選手|
|記事|月|氏|
|月|作|人|
|ビデオ|作品|る|
|売れ筋|本|戦|
|iPhone|女|日|
|テレビ|彼|サッカー|
|新|日本|Sports|
|SALON|日|さん|
<img src="https://user-images.githubusercontent.com/65235517/152645458-6021d778-a0d6-4288-a326-e4205fe57506.png" width="50%">

今回の実験ではFastTextを用いて300次元のベクトルに加工した．
そのベクトル空間では近い意味(同じ文脈で出現する)の単語が近くに現れる．

上に示した図は今回分類した3トピックごとに頻出した単語の単語ベクトルをを2次元に圧縮してプロットしたものである．
トピックと連想できる単語が頻出しており，また，ベクトル空間上でもトピックごとに現れる単語に偏りがあることが確認できる．

以上より，単語を分散表現に変換しその総和を文書のベクトルとして定義しても，その特徴量は失われないと考えられる．

### 疑似F値について

今回の実験ではクラスタリング結果について，精度のほかに疑似F値を用いて比較した．

クラスタ間分散とクラスタ内分散の比から算出される．
クラスタ同士は疎，かつクラスタ内は密になっている場合にいい評価を与える．
大きな値であるほど良い．
+ 𝑃𝑠𝑒𝑢𝑑𝑜𝐹=((𝑇−𝑃𝑔)/(𝐺−1))/(𝑃𝑔/(𝑛−𝐺))
    * G	:クラスタ数
    * n	:全データ数
    * T	:全データの距離2乗和
    * Pg	:クラスタ内距離2乗和
 
### 比較結果について
以下は10回実行した結果の平均を示したものである．
||AntTree|K-Means|
|:--|:--:|:--:|
|平均正答数|2380.7|2530.2|
|平均正答数|0.9038|0.9601|
|疑似F値|131.6|260.1|

群知能を用いたクラスタリングは成功したといえる．
ただし，今回の実験においてはK-Means法の方が精度が良い結果になった．
また，K-Means法の方がベクトル空間内でよりクラスタがまとまるようなクラスタリングができていることが分かる．

### クラスタリングについて
<img src="https://user-images.githubusercontent.com/65235517/152645290-57ec8397-7410-463c-af58-4104063cbc08.png" width="50%">

実行毎の精度の差を見てみるとAntTree法の方が実行毎の精度のばらつきが大きいため，K-Means法の方が安定性が高いことが分かった．

### 閾値について
<img src="https://user-images.githubusercontent.com/65235517/152644979-d89b5c73-391a-4ea2-b5d4-3d60191226b3.png" width="50%"><img src="https://user-images.githubusercontent.com/65235517/152644985-0938062b-e9ab-4f52-84a4-14023c3bacd4.png" width="40%">

初期値として与えるアリの接続，移動を決定する閾値は精度に大きく影響しないことが確認できた．
ただし，図で示した範囲を大きく外れるとクラスタリングそのものが失敗したため，データセットごとにある程度の調節は必要だと考えられる．

### その他
* 精度について
  * 形態素解析をした際の単語の損失や文書ベクトルの定義
    * ipa辞書を用いて形態素解析を行ったが，特徴的な単語については語彙の不足によって特徴が失われている可能性がある．
    * 今回の文書ベクトルの定義以外では異なる結果が出るかもしれない．ただし，K-Means法では高精度が得られているため大きく結果を損なってはいないと考えられる．
  * AntTreeの実装，閾値の更新など，パラメータについて
    * 複雑なアルゴリズムを単純なライブラリの関数と比較したため，AntTree法の閾値の更新やパラメータ設定が精度の差につながったのではないかと考えた．
* 評価について
  * 階層クラスタリング
    * AntTree法は階層型クラスタリングであるため，K-Means法など非階層型クラスタリングの手法と比較して，クラスタリング後に分類数を変更できるなどの利点が存在する．
    * 抽象度を下げた，精度以外の視点で比較ができたのではないか．
  * クラスタリング結果の評価尺度
    * 今回用いたF検定以外のクラスタリング評価尺度が存在する．大きく結果が変わることはないと考えるが，AntTree法の特徴を知る手掛かりになったかもしれない．

# reference
*参考文献*
* 群知能とデータマイニング 東京電機大学出版局 Ajith Abraham
* 群知能を用いたデータマイニングに関する研究 専攻科システム工学特別研究 宮本達郎

*引用元*
* Livedoor ニュースコーパス 株式会社ロンウイットが提供しているコーパスを用いた．(省略)

https://www.rondhuit.com/download.html#ldcc

# author
所属 : 熊本高専4年 縄田研究室
hi18noguchi(at)g.kumaoto-nct.ac.jp
